# Rust Cloud Run Orchestrator - Justfile
# Run `just --list` to see all available commands

# Show all available commands
default:
    @just --list

# ============================================================================
# Build & Development
# ============================================================================

# Build the project (debug)
[group('build')]
build:
    cargo build

# Build release version
[group('build')]
build-release:
    cargo build --release

# Check compilation without building
[group('build')]
check:
    cargo check

# Run tests
[group('build')]
test:
    cargo test

# Format code
[group('build')]
fmt:
    cargo fmt

# Run clippy linter
[group('build')]
lint:
    cargo clippy

# Development workflow - rebuild and restart
[group('build')]
dev: build run

# ============================================================================
# Database
# ============================================================================

# Start PostgreSQL with Docker Compose
[group('database')]
db-start:
    docker compose up -d postgres
    @echo "Waiting for PostgreSQL to be ready..."
    @sleep 3

# Stop PostgreSQL
[group('database')]
db-stop:
    docker compose down

# Initialize database (run migrations)
[group('database')]
db-init: db-start
    cargo run --bin ork-cloud-run -- init

# Reset database (WARNING: deletes all data)
[group('database')]
db-reset: db-stop
    docker compose down -v
    @echo "Database reset complete"

# Show database tables
[group('database')]
db-tables:
    docker compose exec postgres psql -U postgres -d orchestrator -c "\dt"

# Query workflows table
[group('database')]
db-workflows:
    docker compose exec postgres psql -U postgres -d orchestrator -c "SELECT id, name, cloud_run_job_name, executor_type FROM workflows;"

# Query runs table
[group('database')]
db-runs:
    docker compose exec postgres psql -U postgres -d orchestrator -c "SELECT id, workflow_id, status, created_at FROM runs ORDER BY created_at DESC LIMIT 10;"

# Query tasks for a specific run
[group('database')]
db-tasks run_id:
    docker compose exec postgres psql -U postgres -d orchestrator -c "SELECT task_index, status, cloud_run_execution_name, finished_at FROM tasks WHERE run_id = '{{run_id}}' ORDER BY task_index;"

# ============================================================================
# Orchestrator
# ============================================================================

# Run the orchestrator (default config)
[group('orchestrator')]
run: db-start
    cargo run --bin ork-cloud-run -- run

# Run with optimized config (low-latency, low-memory)
[group('orchestrator')]
run-optimized: db-start
    @echo "Running with optimized config (2s poll, 50 batch, 5 concurrent)"
    RUST_LOG=info cargo run --release --bin ork-cloud-run -- run

# Run with high-throughput config
[group('orchestrator')]
run-high-throughput: db-start
    @echo "Running with high-throughput config (5s poll, 500 batch, 50 concurrent)"
    RUST_LOG=info cargo run --release --bin ork-cloud-run -- run

# ============================================================================
# Workflows & Runs
# ============================================================================

# List all workflows
[group('workflows')]
workflows:
    cargo run --bin ork-cloud-run -- list-workflows

# Create example workflow (process executor)
[group('workflows')]
workflow-create-example:
    @cargo run --bin ork-cloud-run -- create-workflow \
        --name "example-process" \
        --description "Example workflow with process executor" \
        --job-name "example-task.sh" \
        --project "local" \
        --region "local" \
        --task-count 5 \
        --executor process 2>/dev/null || echo "Workflow 'example-process' already exists (skipped)"

# Create Cloud Run workflow
[group('workflows')]
workflow-create name job project="my-project" region="us-central1" tasks="3":
    cargo run --bin ork-cloud-run -- create-workflow \
        --name {{name}} \
        --job-name {{job}} \
        --project {{project}} \
        --region {{region}} \
        --task-count {{tasks}} \
        --executor cloudrun

# Trigger a workflow
[group('workflows')]
trigger workflow:
    cargo run --bin ork-cloud-run -- trigger {{workflow}}

# Show all run statuses
[group('workflows')]
status:
    cargo run --bin ork-cloud-run -- status

# Show status of specific run
[group('workflows')]
status-run run_id:
    cargo run --bin ork-cloud-run -- status {{run_id}}

# Show runs for a workflow
[group('workflows')]
status-workflow workflow:
    cargo run --bin ork-cloud-run -- status --workflow {{workflow}}

# Show tasks for a run
[group('workflows')]
tasks run_id:
    cargo run --bin ork-cloud-run -- tasks {{run_id}}

# ============================================================================
# Docker
# ============================================================================

# Build Docker image
[group('docker')]
docker-build:
    docker build -t rust-orchestrator .

# Start all services with Docker Compose
[group('docker')]
docker-up:
    docker compose up -d
    @echo "Waiting for services to start..."
    @sleep 5
    docker compose exec orchestrator /app/rust-orchestrator init

# Stop all Docker services
[group('docker')]
docker-down:
    docker compose down

# Execute command in orchestrator container
[group('docker')]
docker-exec *ARGS:
    docker compose exec orchestrator /app/rust-orchestrator {{ARGS}}

# View orchestrator logs
[group('docker')]
docker-logs:
    docker compose logs -f orchestrator

# Create example workflow in Docker
[group('docker')]
docker-workflow-create:
    docker compose exec orchestrator /app/rust-orchestrator create-workflow \
        --name "docker-example" \
        --job-name "example-task" \
        --project "my-project" \
        --task-count 3 \
        --executor process

# Trigger workflow in Docker
[group('docker')]
docker-trigger workflow:
    docker compose exec orchestrator /app/rust-orchestrator trigger {{workflow}}

# View status in Docker
[group('docker')]
docker-status:
    docker compose exec orchestrator /app/rust-orchestrator status

# ============================================================================
# Testing & Setup
# ============================================================================

# Complete first-time setup
[group('setup')]
setup: db-start db-init test-script-create workflow-create-example
    @echo ""
    @echo "✓ Setup complete!"
    @echo ""
    @echo "Next steps:"
    @echo "  just trigger example-process  # Trigger the example workflow"
    @echo "  just run                      # Start the orchestrator"
    @echo "  just status                   # Check run status"

# Create test script for process executor
[group('setup')]
test-script-create:
    @echo "✓ Test script already exists at test-scripts/example-task.sh"

# Run end-to-end test
[group('testing')]
test-e2e: db-start db-init test-script-create workflow-create-example
    ./scripts/test-e2e.sh

# Run load test (100 workflows)
[group('testing')]
test-load: db-start db-init workflow-create-example
    ./scripts/test-load.sh

# Run performance test with custom parameters
[group('perf')]
perf workflows="100" tasks="5" duration="0.1": db-start db-init clean-data
    cargo run --release --bin perf-test -- --workflows {{workflows}} --tasks-per-workflow {{tasks}} --duration {{duration}}

# Quick smoke test (10 runs, 5 tasks/run)
[group('perf')]
perf-quick: db-start db-init clean-data
    cargo run --release --bin perf-test -- --config quick

# Standard load test (100 runs, 5 tasks/run)
[group('perf')]
perf-standard: db-start db-init clean-data
    cargo run --release --bin perf-test -- --config standard

# Heavy load test (1000 runs, 10 tasks/run)
[group('perf')]
perf-heavy: db-start db-init clean-data
    cargo run --release --bin perf-test -- --config heavy

# Latency test (measure scheduling overhead)
[group('perf')]
perf-latency: db-start db-init clean-data
    cargo run --release --bin perf-test -- --config latency

# Memory test (long-running concurrent tasks)
[group('perf')]
perf-memory: db-start db-init clean-data
    cargo run --release --bin perf-test -- --config memory

# Run all performance tests
[group('perf')]
perf-all: db-start db-init
    #!/usr/bin/env bash
    set -e
    mkdir -p perf-results
    timestamp=$(date +%Y%m%d-%H%M%S)
    for config in perf-configs/*.yaml; do
        name=$(basename "$config" .yaml)
        echo ""
        echo "========================================"
        echo "Running performance test: $name"
        echo "========================================"
        just clean-data
        output_file="perf-results/${timestamp}-${name}.txt"
        cargo run --release --bin perf-test -- --config "$name" | tee "$output_file"
        echo "Results saved to: $output_file"
    done
    echo ""
    echo "========================================"
    echo "All performance tests completed"
    echo "Results saved in perf-results/${timestamp}-*.txt"
    echo "========================================"

# ============================================================================
# Cleanup
# ============================================================================

# Clean build artifacts
[group('cleanup')]
clean:
    cargo clean
    rm -rf target

# Clean test artifacts
[group('cleanup')]
clean-test:
    rm -rf test-scripts

# Clean database data (keep schema)
[group('cleanup')]
clean-data:
    docker compose exec postgres psql -U postgres -d orchestrator -c "DELETE FROM tasks; DELETE FROM runs;"
    @echo "✓ Database data cleaned"

# Clean everything (build + test + db)
[group('cleanup')]
clean-all: clean clean-test db-reset
    @echo "✓ All cleaned"
